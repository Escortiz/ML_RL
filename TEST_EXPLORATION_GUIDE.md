# üéÆ Gu√≠a R√°pida: C√≥mo Cambiar el Modo de Evaluaci√≥n en test.py

## ‚úÖ RESPUESTA CORTA

**NO necesitas cambiar c√≥digo directamente.** Ahora hay un **par√°metro `--exploration`** que puedes usar desde l√≠nea de comandos.

---

## üéØ C√≥mo Usar

### **Modo 1: EVALUACI√ìN DETERMINISTA (default)**
```bash
python3.8 test.py --model model.mdl --episodes 10
```
‚úÖ El Hopper toma la acci√≥n MEDIA (determinista)
‚úÖ Sin exploraci√≥n (posici√≥n congelada si el modelo as√≠ lo aprendi√≥)
‚úÖ Esto es lo que VES por defecto (comportamiento congelado)

---

### **Modo 2: EVALUACI√ìN CON EXPLORACI√ìN (nuevo)**
```bash
python3.8 test.py --model model.mdl --episodes 10 --exploration
```
‚úÖ El Hopper EXPLORA (acciones aleatorias con varianza)
‚úÖ Comportamiento menos determinista
‚úÖ Ver si el modelo realmente aprendi√≥ patrones o solo memoriz√≥

---

## üìã Par√°metros Completos

```bash
# Evaluaci√≥n b√°sica (determinista)
python3.8 test.py --model model.mdl

# Evaluaci√≥n con exploraci√≥n
python3.8 test.py --model model.mdl --exploration

# Evaluaci√≥n con m√°s episodios
python3.8 test.py --model model.mdl --episodes 100

# Evaluaci√≥n con video
python3.8 test.py --model model.mdl --episodes 5 --record-video --record-every 1

# Evaluaci√≥n con exploraci√≥n + video + m√∫ltiples episodios
python3.8 test.py --model model.mdl --episodes 20 --exploration --record-video --record-every 2

# Training mode (dentro del test.py)
python3.8 test.py --train --episodes 5000

# Training con exploraci√≥n (por defecto ya lo tiene)
python3.8 test.py --train --episodes 5000 --save-every 500 --device cuda
```

---

## üîç C√≥mo Ver la Diferencia

### **Paso 1: Ejecutar en modo determinista**
```bash
python3.8 test.py --model model.mdl --episodes 3
```

Ver√°s en console:
```
======================================================================
MODO: EVALUACI√ìN DETERMINISTA (deterministic - mean actions)
======================================================================

Episode: 1/3 | Return: 5.23
Episode: 2/3 | Return: 5.23
Episode: 3/3 | Return: 5.23

Average return over 3 episodes: 5.23
```

‚ö†Ô∏è Si el `Return` es **muy similar en todos los episodios** ‚Üí Modelo tom√≥ acciones fijas

---

### **Paso 2: Ejecutar en modo con exploraci√≥n**
```bash
python3.8 test.py --model model.mdl --episodes 3 --exploration
```

Ver√°s en console:
```
======================================================================
MODO: EVALUACI√ìN CON EXPLORACI√ìN (stochastic - actions aleatorias)
======================================================================

Episode: 1/3 | Return: 4.56
Episode: 2/3 | Return: 7.89
Episode: 3/3 | Return: 6.12

Average return over 3 episodes: 6.19
```

‚úÖ Si el `Return` **var√≠a en cada episodio** ‚Üí Hay exploraci√≥n

---

## üß† Interpretaci√≥n de Resultados

| Escenario | Determinista | Con Exploraci√≥n | Conclusi√≥n |
|-----------|---|---|---|
| Mismos Returns | ‚úÖ 5.2, 5.2, 5.2 | ‚ùå 5.2, 5.2, 5.2 | Modelo tiene pol√≠tica fija |
| Returns variados | ‚ö†Ô∏è 5.2, 5.2, 5.2 | ‚úÖ 4.1, 7.3, 6.5 | Modelo aprende pero con exploraci√≥n mejora |
| Returns muy altos | ‚úÖ 150, 150, 150 | ‚úÖ 145, 155, 148 | Modelo entrenado bien |
| Returns muy bajos | ‚ùå 1.2, 1.2, 1.2 | ‚ùå 0.8, 1.5, 1.1 | Modelo NO entrenado bien |

---

## üìä Qu√© Cambi√≥ en el C√≥digo

### **Antes:**
```python
# En test.py l√≠nea 153
action, _ = agent.get_action(state, evaluation=True)  # Siempre determinista
```

### **Despu√©s:**
```python
# En test.py l√≠nea ~155
evaluation_mode = not args.exploration
action, _ = agent.get_action(state, evaluation=evaluation_mode)

# Si --exploration: evaluation=False (estoc√°stico)
# Si sin --exploration: evaluation=True (determinista)
```

---

## ‚ö° Resumen de Comandos √ötiles

```bash
# Ver ayuda de todos los par√°metros
python3.8 test.py --help

# Test determinista (congelado si entrenamiento insuficiente)
python3.8 test.py --model model.mdl

# Test con exploraci√≥n (ver variabilidad)
python3.8 test.py --model model.mdl --exploration

# Test con video para visualizar diferencia
python3.8 test.py --model model.mdl --episodes 3 --record-video
python3.8 test.py --model model.mdl --episodes 3 --record-video --exploration

# Comparar ambos modos
# Terminal 1:
python3.8 test.py --model model.mdl --episodes 5 --video-folder videos_determinista

# Terminal 2:
python3.8 test.py --model model.mdl --episodes 5 --exploration --video-folder videos_exploracion
```

---

## üí° Recomendaci√≥n

Para diagnosticar tu problema de "modelo congelado":

1. **Ejecuta sin exploraci√≥n (default):**
   ```bash
   python3.8 test.py --model model.mdl --episodes 5
   ```
   Anota los valores de `Return`

2. **Ejecuta con exploraci√≥n:**
   ```bash
   python3.8 test.py --model model.mdl --episodes 5 --exploration
   ```
   Anota los valores de `Return`

3. **Compara:**
   - Si ambos tienen `Return ~1-5` ‚Üí Modelo no fue entrenado bien
   - Si sin exploraci√≥n tiene `Return ~5` pero con exploraci√≥n `~20` ‚Üí Modelo aprende pero necesita m√°s regularizaci√≥n
   - Si ambos tienen `Return ~200` ‚Üí Modelo est√° bien entrenado

---

## üé¨ Ejemplo Completo

```bash
# Entrenamiento (en Colab con GPU)
python3.8 train.py --n-episodes 10000 --print-every 1000 --device cuda

# Guardar modelo
# (Se guarda autom√°ticamente como model.mdl)

# Test determinista (ver si est√° congelado)
python3.8 test.py --model model.mdl --episodes 3

# Test con exploraci√≥n (ver si hay variabilidad)
python3.8 test.py --model model.mdl --episodes 3 --exploration

# Test con video para an√°lisis visual
python3.8 test.py --model model.mdl --episodes 2 --record-video --exploration
```

---

¬°Listo! Ahora puedes cambiar el modo de evaluaci√≥n sin modificar c√≥digo, solo usando el par√°metro `--exploration`. üöÄ
